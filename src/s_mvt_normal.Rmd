---
title: "Multivariate normal example"
output: html_notebook
---

```{r}
rm(list=ls())
library(tidyverse)
library(reshape2)
library(rstan)
library(latex2exp)
library(caret)
library(gbm)
library(mvtnorm)
options(mc.cores=4)
rstan_options(auto_write = TRUE)
source("monitornew.R")
source("r_star_monitor.R")

caretGrid <- expand.grid(interaction.depth=c(3), n.trees = 50,
                   shrinkage=c(0.1),
                   n.minobsinnode=10)
```

# Centered and non-centered parameterisations
Fit centered model in Stan with 10000 iterations and look at variable importance
```{r}
# N <- 250
# A <- rWishart(1, 250, diag(N))[,,1]
# saveRDS(A, "../output/A_matrix.rds")
# A <- readRDS("../output/A_matrix.rds")
# model <- stan_model("mvt_250.stan")
# fit <- sampling(model, data=list(N=N, A=A), iter=10000, chains=4, thin=5)
# saveRDS(fit, "../output/mvt_fit_10000.rds")
fit <- readRDS("../output/mvt_fit_10000.rds")

# Collect Rhat and calculate as in posterior package
full_data <- rstan::extract(fit, permuted=F)
a_sum <- monitor_extra(full_data)
rhat <- a_sum$zfsRhat
rhat1 <- a_sum$zsRhat
rhat <- tibble(rhat, rhat1) %>% 
  apply(1, max)

# Reshape data into form for R* estimation
m_flattened <- matrix(nrow = nrow(full_data) * 4, ncol = 252)
k <- 1
for(i in 1:4){
  for(j in 1:nrow(full_data)){
    m_flattened[k, 1:251] <- full_data[j, i, ]
    m_flattened[k, 252] <- i
    k <- k + 1
  }
}
m_flattened <- m_flattened %>% 
  as.data.frame() %>% 
  rename(chain=V252) %>% 
  mutate(chain=as.factor(chain))

full_data <- m_flattened
rand_samples <- sample(1:nrow(full_data), 0.7 * nrow(full_data))
training_data <- full_data[rand_samples, ]
testing_data <- full_data[-rand_samples, ]

# Fit gradient-boosed model
gbmFit1 <- train(chain ~ ., data = training_data, 
                 method = "gbm",
                 trControl = trainControl(method = 'none'), 
                    tuneGrid = caretGrid, verbose=FALSE)

# Get R* distribution
full_data <- rstan::extract(fit, permuted=F)
a_df <- tibble(samples_10000_cp_gbm=r_star(full_data, uncertainty = T, method="gbm"),
               samples_10000_cp_rf=r_star(full_data, uncertainty = T, method="rf"))

importance <- 100-varImp(gbmFit1)$importance$Overall
ess_b <- a_sum$zsseff
ess_t <- a_sum$tailseff
b_df <- tibble(importance, ess_b, ess_t, rhat, lp=c(rep(0, 250), 1))
mean(rhat<1.01)
mean(ess_b<400)
mean(ess_t<400)
cor.test(b_df$importance, b_df$rhat, method="spearman")
cor.test(b_df$importance, b_df$ess_b, method="spearman")
cor.test(b_df$importance, b_df$ess_t, method="spearman")
gc <- b_df %>%
  select(importance, ess_b, ess_t, lp) %>% 
  melt(id.vars=c("importance", "lp")) %>% 
  ggplot(aes(importance, value)) +
  geom_jitter(width=1, aes(shape=as.factor(lp), colour=as.factor(variable))) +
  geom_smooth(span=1, aes(colour=as.factor(variable))) +
  xlab("Variable importance") +
  ylab("ESS") +
  ggtitle("D.") +
  scale_color_grey("ESS type", labels=c("Bulk", "Tail")) +
  scale_shape("LP param", labels=c("False", "True")) +
  theme(legend.position = c(0.85, 0.6),
        text = element_text(size=18, colour="black"),
        axis.text = element_text(colour="black"))

gb <- b_df %>%
  ggplot(aes(importance, rhat)) +
  geom_jitter(width = 1, aes(shape=as.factor(lp)), colour='grey') +
  geom_smooth(span=1, colour="black") +
  xlab("Variable importance") +
  ylab(TeX("Split-$\\hat{R}$")) +
  ggtitle("C.") +
  theme(legend.position = "none",
        text = element_text(size=18, colour="black"),
        axis.text = element_text(colour="black"))
b_df <- tibble(samples_10000_cp=rhat[1:250])
```

With 400 iterations
```{r}
source("monitornew.R")
# fit <- sampling(model, data=list(N=N, A=A), iter=400, chains=4)
# print(fit)
# saveRDS(fit, "../output/mvt_fit_400.rds")
fit <- readRDS("../output/mvt_fit_400.rds")

full_data <- rstan::extract(fit, permuted=F)
r_star2_gbm <- r_star(full_data, uncertainty = T, method="gbm")
r_star2_rf <- r_star(full_data, uncertainty = T, method="rf")

a_df <- a_df %>%
  mutate(samples_400_gbm=r_star2_gbm,
         samples_400_rf=r_star2_rf)
a_sum <- monitor_extra(full_data)
rhat <- a_sum$zfsRhat
rhat1 <- a_sum$zsRhat
rhat <- tibble(rhat, rhat1) %>% 
  apply(1, max)
b_df <- b_df %>%
  mutate(samples_400=rhat[1:250])
```

10,000 iterations for non-centered parameterisation
```{r}
# model <- stan_model("mvt_250_ncp.stan")
# fit <- sampling(model, data=list(N=N, A=A), iter=10000, chains=4, thin=5)
# print(fit)
# saveRDS(fit, "../output/mvt_ncp_fit_10000.rds")
fit <- readRDS("../output/mvt_ncp_fit_10000.rds")
full_data <- rstan::extract(fit, permuted=F)
a_sum <- monitor_extra(full_data)
sum(a_sum$zsseff>400)
sum(a_sum$tailseff>400)
sum(a_sum$zfsRhat<1.01)
sum(a_sum$zsRhat<1.01)
rhat <- a_sum$zfsRhat
rhat1 <- a_sum$zsRhat
rhat <- tibble(rhat, rhat1) %>% 
  apply(1, max)
b_df <- b_df %>%
  mutate(samples_10000_ncp=rhat[251:500])
saveRDS(b_df, "../output/mvt_fit_all_rhat.rds")
b_df <- readRDS("../output/mvt_fit_all_rhat.rds")


r_star3_gbm <- r_star(full_data, uncertainty = T, method = "gbm")
r_star3_rf <- r_star(full_data, uncertainty = T, method = "rf")

a_df <- a_df %>%
  mutate(samples_10000_ncp_gbm=r_star3_gbm,
         samples_10000_ncp_rf=r_star3_rf)

saveRDS(a_df, "../output/mvt_fit_all_accuracy.rds")
a_df <- readRDS("../output/mvt_fit_all_accuracy.rds")
a_df_gbm <- a_df %>%
  select(contains("gbm")) %>% 
  rename(samples_10000_cp=samples_10000_cp_gbm,
         samples_400=samples_400_gbm,
         samples_10000_ncp=samples_10000_ncp_gbm) %>% 
  mutate(Classifier="A. GBM")
a_df_rf <- a_df %>%
  select(contains("rf")) %>% 
  rename(samples_10000_cp=samples_10000_cp_rf,
         samples_400=samples_400_rf,
         samples_10000_ncp=samples_10000_ncp_rf) %>% 
  mutate(Classifier="B. RF")
  

ga <- 
  a_df_gbm %>% 
  melt() %>% 
  ggplot(aes(x=value, fill=fct_relevel(as.factor(variable), "samples_400", "samples_10000_cp", "samples_10000_ncp"))) +
  geom_histogram(position="identity", alpha=0.8, bins=50) +
  scale_fill_grey("# draws", labels=c("400, cp", "10,000, cp", "10,000, ncp")) +
  xlab(TeX("$R*$")) +
  ylab("Count") +
  geom_vline(xintercept = 1, linetype=2) +
  theme(text = element_text(size=18, colour="black"),
        legend.position = c(0.8, 0.75),
        axis.text = element_text(colour="black")) +
  ggtitle("A.")

ga2 <- 
  b_df %>% 
  melt() %>% 
  ggplot(aes(x=value, fill=fct_relevel(as.factor(variable), "samples_400", "samples_10000_cp", "samples_10000_ncp"))) +
  geom_histogram(position="identity", alpha=0.8, bins=60) +
  scale_fill_grey("# draws", labels=c("400, cp", "10,000, cp", "10,000, ncp")) +
  xlab(TeX("Split-$\\hat{R}$")) +
  ylab("Count") +
  geom_vline(xintercept = 1, linetype=2) +
  theme(text = element_text(size=18, colour="black"),
        axis.text = element_text(colour="black"),
        legend.position = c(0.8, 0.75)) +
  ggtitle("B.")

pdf("../output/mvt_three.pdf", width = 12, height = 8)
multiplot(ga, gb, ga2, gc, cols = 2)
dev.off()


# provide GBM vs RF results in supplementary
ga1 <- 
  a_df_gbm %>% 
  bind_rows(a_df_rf) %>% 
  melt() %>% 
  ggplot(aes(x=value, fill=fct_relevel(as.factor(variable), "samples_400", "samples_10000_cp", "samples_10000_ncp"))) +
  geom_histogram(position="identity", alpha=0.8, bins=50) +
  scale_fill_grey("# draws", labels=c("400, cp", "10,000, cp", "10,000, ncp")) +
  xlab(TeX("$R*$")) +
  ylab("Count") +
  geom_vline(xintercept = 1, linetype=2) +
  theme(text = element_text(size=18, colour="black"),
        legend.position = c(0.8, 0.75),
        axis.text = element_text(colour="black")) +
  facet_wrap(~Classifier)
ggsave("../output/mvt_gbm_vs_rf.pdf", ga1, width = 12, height = 4)

a_df_gbm %>% 
  bind_rows(a_df_rf) %>% 
  melt() %>% 
  group_by(Classifier, variable) %>% 
  summarise(value=mean(value)) %>% 
  pivot_wider(id_cols = "variable", names_from = "Classifier", values_from = "value")
```

