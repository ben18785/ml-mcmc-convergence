---
title: "Comparing gbm vs rf (default parameterisations)"
output: html_notebook
---

```{r}
rm(list=ls())
library(tidyverse)
library(reshape2)
library(rstan)
library(latex2exp)
library(caret)
library(gbm)
options(mc.cores=4)
rstan_options(auto_write = TRUE)
source("monitornew.R")
source("r_star_monitor.R")
```


# Different covariance matrices
```{r}
rlkj <- function(n, nu, d){
  r_list <- vector(length = n, mode = 'list')
  for(i in 1:n){
    if(d==1)
      r = as.array(1)
    else if(d==2){
      rho <- 2 * rbeta(1, nu, nu) - 1
      r <- matrix(c(1, rho, rho, 1), ncol = 2)
    }else{
      beta <- nu + (d - 2) / 2
      u <- rbeta(1, beta, beta)
      r_12 <- 2 * u - 1
      r <- matrix(c(1, r_12, r_12, 1), ncol = 2)
      for(m in 2:(d - 1)){
        beta <- beta - 0.5
        y <- rbeta(1, m / 2, beta)
        a <- rnorm(m)
        anorm <- sqrt(sum(a^2))
        u <- a / anorm
        w <- sqrt(y) * u
        A <- chol(r)
        z <- w%*%A
        r <-cbind(r, t(z))
        r <- rbind(r, c(z, 1))
      }
    }
    r_list[[i]] <- r
  }
  return(r_list)
}
# d <- 32
# A0 <- rlkj(1, 1, d)[[1]]
# A1 <- rlkj(1, 1, d)[[1]]
# saveRDS(list(A0=A0, A1=A1), "../data/xgbTree_vs_rf_normals.rds")
temp <- readRDS("../data/xgbTree_vs_rf_normals.rds")
A0 <- temp$A0
A1 <- temp$A1

library(mvtnorm)
f_data_normals <- function(A0, A1, d, niter=2000){
  x <- array(dim=c(niter, 4, d))
  if(d > 1){
    for(i in 1:3)
      x[, i, ] <- rmvnorm(niter, rep(0, d), A0[1:d, 1:d])
    x[ , 4, ] <- rmvnorm(niter, rep(0, d), A1[1:d, 1:d])
  }else{
    for(i in 1:3)
      x[, i, ] <- rnorm(niter, rep(0, d), A0[1:d, 1:d])
    x[ , 4, ] <- rnorm(niter, rep(0, d), A1[1:d, 1:d])
  }
  return(x)
}

f_compare_rf_gbm <- function(d, A0, A1){
  lrstar <- vector(length=2)
  ltimes <- vector(length=2)
  x <- f_data_normals(A0, A1, d)
  start <- Sys.time()
  lrstar[1] <- r_star(x, method="rf")
  end <- Sys.time()
  ltimes[1] <- end-start
  start <- Sys.time()
  lrstar[2] <- r_star(x, method="gbm")
  end <- Sys.time()
  ltimes[2] <- end-start
  return(list(rstar=lrstar, time=ltimes))
}

f_compare_iter <- function(nreplicate, d, A0, A1){
  m_res <- matrix(nrow=nreplicate, ncol=6)
  for(i in 1:nreplicate){
    temp <- f_compare_rf_gbm(d, A0, A1)
    rstars <- temp$rstar
    times <- temp$time
    m_res[i, ] <- c(i, d, rstars[1], rstars[2], times[1], times[2])
  }
  colnames(m_res) <- c("iter", "d", "rstar_rf", "rstar_gbm", "time_rf", "time_gbm")
  m_res <- m_res %>% 
    as.data.frame()
  return(m_res)
}

# Run replicates with one chain with a different cov matrix
nreplicates <- 20
ds <- c(1, 2, 4, 8, 16, 32)
for(i in seq_along(ds)){
  print(i)
  temp_df <- f_compare_iter(nreplicates, ds[i], A0, A1)
  if(i==1)
    big_df <- temp_df
  else
    big_df <- big_df %>% bind_rows(temp_df)
}
saveRDS(big_df, "../data/gbm_vs_rf_normals_results.rds")

# work out optimal classification rates
f_optimal_normals <- function(niter, A0, A1, d){
  x <- f_data_normals(A0, A1, d, niter)
  A0_temp <- A0[1:d, 1:d]
  A1_temp <- A1[1:d, 1:d]
  if(d > 1){
    f_first <- function(x) dmvnorm(x, rep(0, d), A0_temp)
    f_second <- function(x) dmvnorm(x, rep(0, d), A1_temp)
  }else{
    f_first <- function(x) dnorm(x, 0, A0_temp)
    f_second <- function(x) dnorm(x, 0, A1_temp)
  }
  m_class <- matrix(nrow = dim(x)[1], ncol = dim(x)[2])
  for(i in 1:dim(x)[1]){
    for(j in 1:dim(x)[2]){
      prob0 <- f_first(x[i, j,])
      prob1 <- f_second(x[i, j,])
      if(prob0 > prob1)
        m_class[i, j] <- 0
      else
        m_class[i, j] <- 1
    }
  }
  a0 <- 1/3 * 1/3 * (mean(m_class[, 1]==0) + mean(m_class[, 2]==0) + mean(m_class[, 3]==0))
  a1 <- mean(m_class[, 4]==1)
  return(1/4 * (3 * a0 + a1) / 0.25)
}

r_star_opts <- map_dbl(ds[2:length(ds)], ~f_optimal_normals(10000, A0, A1, .))
r_star_opts <- c(1, r_star_opts)
r_star_opts <- tibble(d=ds, optimal=r_star_opts)

# plot results
temp_df <- 
  big_df %>%
  left_join(r_star_opts) %>% 
  select(-contains("time")) %>% 
  melt(id.vars=c("iter", "d")) %>% 
  group_by(variable, d) %>% 
  summarise(lower=quantile(value, 0.25),
            middle=quantile(value, 0.5),
            upper=quantile(value, 0.75)) %>% 
  ungroup() %>% 
  mutate(variable=as.character(variable)) %>% 
  mutate(variable=if_else(variable=="rstar_rf", "rf", if_else(variable=="rstar_gbm", "gbm", "optimal")))
saveRDS(temp_df, "../data/gbm_vs_rf_normals_results_optimals.rds")
temp_df <- readRDS("../data/gbm_vs_rf_normals_results_optimals.rds") %>% 
  mutate(variable=as.character(variable)) %>% 
  mutate(variable=if_else(variable=="gbm", "GBM",
                          if_else(variable=="rf", "RF", "Optimal"))) %>% 
  mutate(variable=fct_relevel(as.factor(variable), "GBM", "RF", "Optimal"))
g <- ggplot(temp_df,
       aes(x=as.factor(d), y=middle, colour=as.factor(variable),
           shape=as.factor(variable))) +
  geom_pointrange(aes(ymin=lower, ymax=upper),
                  position = position_dodge2(width=0.3)) +
  geom_hline(yintercept = 1, linetype=2) +
  scale_color_grey("Method", start=0.8, end=0) +
  scale_shape("Method") +
  xlab("# dimensions") +
  ylab("R*") +
  theme(text = element_text(size=16, colour="black"),
        axis.text = element_text(colour="black"))
ggsave("../output/gbm_vs_rf_normal.pdf", g, width = 10, height = 6)
```

# Tail fatness
```{r}
library(LaplacesDemon)
f_data_student_ts <- function(nu1, nu2, d, A0, niter=2000){
  x <- array(dim=c(niter, 4, d))
  # ensures variance stays same
  sigma1 <- A0[1:d, 1:d] * (nu1 - 2) / nu1
  sigma2 <- A0[1:d, 1:d] * (nu2 - 2) / nu2
  if(d > 1){
    for(i in 1:3)
      x[, i, ] <- mvtnorm::rmvt(niter, sigma=sigma1, df=nu1, delta=rep(0, d))
    x[ , 4, ] <- mvtnorm::rmvt(niter, sigma=sigma2, df=nu2, delta=rep(0, d))
  }else{
    for(i in 1:3)
      x[, i, ] <- LaplacesDemon::rst(niter, 0, sqrt(sigma1), nu1)
    x[ , 4, ] <- LaplacesDemon::rst(niter, 0, sqrt(sigma2), nu2)
  }
  return(x)
}

# x <- f_data_student_ts(3, 100, 1, A0, niter=10000)
library(e1071)   
# kurtosis(x[, 2, 1])
# kurtosis(x[, 1, 1])
# kurtosis(x[, 3, 1])
# kurtosis(x[, 4, 1])
# sd(x[, 2, 1])
# sd(x[, 1, 1])
# sd(x[, 3, 1])
# sd(x[, 4, 1])

f_compare_rf_gbm_student_ts <- function(nu1, nu2, d, A0){
  lrstar <- vector(length=2)
  ltimes <- vector(length=2)
  x <- f_data_student_ts(nu1, nu2, d, A0)
  start <- Sys.time()
  lrstar[1] <- r_star(x, method="rf")
  end <- Sys.time()
  ltimes[1] <- end-start
  start <- Sys.time()
  lrstar[2] <- r_star(x, method="gbm")
  end <- Sys.time()
  ltimes[2] <- end-start
  return(list(rstar=lrstar, time=ltimes))
}

f_compare_iter_student_t <- function(nreplicate, nu1, nu2, d, A0){
  m_res <- matrix(nrow=nreplicate, ncol=8)
  for(i in 1:nreplicate){
    temp <- f_compare_rf_gbm_student_ts(nu1, nu2, d, A0)
    rstars <- temp$rstar
    times <- temp$time
    m_res[i, ] <- c(i, d, nu1, nu2, rstars[1], rstars[2], times[1], times[2])
  }
  colnames(m_res) <- c("iter", "d", "nu1", "nu2", "rstar_rf", "rstar_gbm", "time_rf", "time_gbm")
  m_res <- m_res %>% 
    as.data.frame()
  return(m_res)
}

# Run replicates
nreplicates <- 20
nu1 <- 3
nu2 <- c(4, 8, 16, 32)
ds <- c(1, 2, 4, 8, 16, 32)
m_parameters <- expand_grid(nu2, ds)

for(i in 1:nrow(m_parameters)){
  print(i)
  temp_df <- f_compare_iter_student_t(nreplicates, nu1, m_parameters$nu2[i], m_parameters$ds[i], A0)
  if(i==1)
    big_df <- temp_df
  else
    big_df <- big_df %>% bind_rows(temp_df)
}
saveRDS(big_df, "../data/gbm_vs_rf_studentts_results.rds")

# calculate optimal classification rates
f_optimal_studentts <- function(niter, nu1, nu2, d, A0){
  x <- f_data_student_ts(nu1, nu2, d, A0, niter = niter)
  sigma1 <- A0[1:d, 1:d] * (nu1 - 2) / nu1
  sigma2 <- A0[1:d, 1:d] * (nu2 - 2) / nu2
  if(d > 1){
    f_first <- function(x) dmvt(x, rep(0, d), sigma1, nu1)
    f_second <- function(x) dmvt(x, rep(0, d), sigma2, nu2)
  }else{
    f_first <- function(x) dst(x, 0, sigma1, nu1)
    f_second <- function(x) dst(x, 0, sigma2, nu2)
  }
  m_class <- matrix(nrow = dim(x)[1], ncol = dim(x)[2])
  for(i in 1:dim(x)[1]){
    for(j in 1:dim(x)[2]){
      prob0 <- f_first(x[i, j,])
      prob1 <- f_second(x[i, j,])
      if(prob0 > prob1)
        m_class[i, j] <- 0
      else
        m_class[i, j] <- 1
    }
  }
  a0 <- 1/3 * 1/3 * (mean(m_class[, 1]==0) + mean(m_class[, 2]==0) + mean(m_class[, 3]==0))
  a1 <- mean(m_class[, 4]==1)
  return(1/4 * (3 * a0 + a1) / 0.25)
}

r_star_opts1 <- map_dbl(seq(1, nrow(m_parameters), 1), ~f_optimal_studentts(10000, nu1, m_parameters$nu2[.], m_parameters$ds[.], A0))


# plot results
r_star_opts <- tibble(d=m_parameters$ds, nu2=m_parameters$nu2, optimal=r_star_opts1)
big_df <- readRDS("../data/gbm_vs_rf_studentts_results.rds")
temp_df <- 
  big_df %>%
  left_join(r_star_opts) %>% 
  select(-contains("time")) %>% 
  select(-one_of("nu1")) %>% 
  melt(id.vars=c("iter", "d", "nu2")) %>% 
  group_by(variable, d, nu2) %>% 
  summarise(lower=quantile(value, 0.25),
            middle=quantile(value, 0.5),
            upper=quantile(value, 0.75)) %>% 
  ungroup() %>% 
  mutate(variable=as.character(variable)) %>% 
  mutate(variable=if_else(variable=="rstar_rf", "rf", if_else(variable=="rstar_gbm", "gbm", "optimal")))
saveRDS(temp_df, "../data/gbm_vs_rf_studentts_results_optimal.rds")
temp_df <- readRDS("../data/gbm_vs_rf_studentts_results_optimal.rds") %>% 
  mutate(variable=as.character(variable)) %>% 
  mutate(variable=if_else(variable=="gbm", "GBM",
                          if_else(variable=="rf", "RF", "Optimal"))) %>% 
  mutate(variable=fct_relevel(as.factor(variable), "GBM", "RF", "Optimal"))
g2 <- ggplot(data=temp_df,
       aes(x=as.factor(nu2), y=middle, colour=as.factor(variable),
           shape=as.factor(variable))) +
  geom_pointrange(aes(ymin=lower, ymax=upper),
                  position = position_dodge2(width=0.3)) +
  geom_hline(yintercept = 1, linetype=2) +
  scale_color_grey("Method", start=0.8, end=0) +
  scale_shape("Method") +
  xlab("# degrees of freedom") +
  ylab("R*") +
  theme(text = element_text(size=16, colour="black"),
        axis.text = element_text(colour="black")) +
  facet_wrap(~d)
ggsave("../output/gbm_vs_rf_studentt.pdf", g2, width = 12, height = 8)
```

